{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "850144e3-d3c9-4cea-aa8c-f5c59d69e1f7",
      "metadata": {
        "id": "850144e3-d3c9-4cea-aa8c-f5c59d69e1f7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "0589815e-b0ef-448f-8d27-e4326d20229f",
      "metadata": {
        "id": "0589815e-b0ef-448f-8d27-e4326d20229f",
        "outputId": "40e9c9d0-b9a0-4b96-d820-f3d7ef151c2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "\n",
        "\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "e3ef6a01-90dc-480c-8464-536d66e4a861",
      "metadata": {
        "id": "e3ef6a01-90dc-480c-8464-536d66e4a861",
        "outputId": "24a4f4db-a30b-4fee-8b5c-faebc51387d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    # Specify input shape only in the first Conv2D layer\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ebc740fc-4773-4c6a-b39d-4a61581f2082",
      "metadata": {
        "id": "ebc740fc-4773-4c6a-b39d-4a61581f2082",
        "outputId": "9ef9827b-607e-4f37-cda1-0e4ea7200280",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 89ms/step - accuracy: 0.3168 - loss: 1.8497 - val_accuracy: 0.5008 - val_loss: 1.3822\n",
            "Epoch 2/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 84ms/step - accuracy: 0.5276 - loss: 1.3101 - val_accuracy: 0.5730 - val_loss: 1.1824\n",
            "Epoch 3/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 86ms/step - accuracy: 0.5990 - loss: 1.1349 - val_accuracy: 0.5870 - val_loss: 1.1915\n",
            "Epoch 4/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 85ms/step - accuracy: 0.6386 - loss: 1.0191 - val_accuracy: 0.6612 - val_loss: 0.9704\n",
            "Epoch 5/5\n",
            "\u001b[1m704/704\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 84ms/step - accuracy: 0.6770 - loss: 0.9230 - val_accuracy: 0.6684 - val_loss: 0.9830\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.6523 - loss: 0.9971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.6510\n"
          ]
        }
      ],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(f\"Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "# Save the model (optional)\n",
        "model.save('simple_cnn_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "3578179e-2e50-42f5-b007-e2487f76988a",
      "metadata": {
        "id": "3578179e-2e50-42f5-b007-e2487f76988a"
      },
      "outputs": [],
      "source": [
        "# Function to predict the class of an input image\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "def predict_image(image_path):\n",
        "    # Load and preprocess the input image\n",
        "    img = image.load_img(image_path, target_size=(32, 32))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0) / 255.0\n",
        "\n",
        "    # Predict the class\n",
        "    predictions = model.predict(img_array)\n",
        "    predicted_class = np.argmax(predictions, axis=1)[0]\n",
        "\n",
        "    # CIFAR-10 class names\n",
        "    class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "    print(f\"Predicted class: {class_names[predicted_class]}\")\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(img_array[0])\n",
        "    plt.axis('off')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "be592f53-deee-4b14-bb64-b7f1dc96b9e1",
      "metadata": {
        "id": "be592f53-deee-4b14-bb64-b7f1dc96b9e1",
        "outputId": "17678aad-c4ec-4b43-f504-8be123471fbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 144ms/step\n",
            "Predicted class: automobile\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "image_path = \"/ex-3_cnn.jpg\"\n",
        "predict_image(image_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb5299ba-be91-446c-9463-499727bcc578",
      "metadata": {
        "id": "cb5299ba-be91-446c-9463-499727bcc578"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}