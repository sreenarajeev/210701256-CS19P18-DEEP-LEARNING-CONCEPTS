{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "7f76da03-385e-490e-9683-54f5a9487596",
      "metadata": {
        "id": "7f76da03-385e-490e-9683-54f5a9487596"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Load the YOLO model\n",
        "net = cv2.dnn.readNet(\"/yolov3.weights\", \"/yolov3.cfg\")\n",
        "\n",
        "# Load the classes file\n",
        "classes = []\n",
        "with open(\"/labels.name\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# Define the colors for the bounding boxes\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "# Set the input size for the model\n",
        "width = 416\n",
        "height = 416\n",
        "\n",
        "# Set the confidence threshold for object detection\n",
        "confidence_threshold = 0.5\n",
        "\n",
        "# Set the non-max suppression threshold\n",
        "nms_threshold = 0.4\n",
        "\n",
        "# Load the video or image\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "while True:\n",
        "    # Read a frame from the video or image\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert the frame to a blob\n",
        "    blob = cv2.dnn.blobFromImage(frame, 1/255, (width, height), swapRB=True, crop=False)\n",
        "\n",
        "    # Set the input blob for the model\n",
        "    net.setInput(blob)\n",
        "\n",
        "    # Run the model\n",
        "    outputs = net.forward(net.getUnconnectedOutLayersNames())\n",
        "\n",
        "    # Lists to store detected bounding boxes, confidences, and class IDs\n",
        "    boxes = []\n",
        "    confidences = []\n",
        "    class_ids = []\n",
        "\n",
        "    # Loop through the detections\n",
        "    for output in outputs:\n",
        "        for detection in output:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > confidence_threshold:\n",
        "                # Get the bounding box coordinates\n",
        "                center_x = int(detection[0] * frame.shape[1])\n",
        "                center_y = int(detection[1] * frame.shape[0])\n",
        "                w = int(detection[2] * frame.shape[1])\n",
        "                h = int(detection[3] * frame.shape[0])\n",
        "\n",
        "                # Calculate the top-left corner of the bounding box\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "\n",
        "                # Add the box, confidence, and class ID to their respective lists\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Apply Non-Maximum Suppression (NMS)\n",
        "    indices = cv2.dnn.NMSBoxes(boxes, confidences, confidence_threshold, nms_threshold)\n",
        "\n",
        "    # Loop through the remaining boxes after NMS\n",
        "    if len(indices) > 0:\n",
        "        for i in indices.flatten():\n",
        "            x, y, w, h = boxes[i]\n",
        "            color = colors[class_ids[i]]\n",
        "\n",
        "            # Draw the bounding box\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
        "\n",
        "            # Label with class name and confidence\n",
        "            label = f\"{classes[class_ids[i]]}: {confidences[i]:.2f}\"\n",
        "            cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    # Display the output\n",
        "    cv2.imshow(\"Object Detection\", frame)\n",
        "\n",
        "    # Exit on key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the video capture\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}